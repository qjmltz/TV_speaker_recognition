# TV_speaker_recognition
# ç”µè§†å‰§è¯´è¯äººè¯†åˆ«ç«èµ›

<div align="center">
  <img src="./images/image1.png" alt="æ¨¡å‹æ€»è§ˆ" width="200">
  <br>
  <small>åŸºäºæ·±åº¦å­¦ä¹ çš„ç”µè§†å‰§è§’è‰²è¯­éŸ³è¯†åˆ«ç³»ç»Ÿ</small>
</div>

## ğŸ“– é¡¹ç›®æ¦‚è¿°

ç¬¬ä¸ƒå±Šä¸­å›½ç ”ç©¶ç”Ÿäººå·¥æ™ºèƒ½åˆ›æ–°å¤§èµ›å‚èµ›ä½œå“
â€œå£°â€ä¸´å…¶å¢ƒï¼šå¤šæ¨¡æ€é©±åŠ¨çš„æ™ºèƒ½å°è¯æ ‡æ³¨ç³»ç»Ÿ 
é’ˆå¯¹ä¼ ç»Ÿå­—å¹•åˆ¶ä½œä¸­å°è¯å¯¹é½ä¾èµ–äººå·¥ã€è¯¯å·®ç‡é«˜çš„ç—›ç‚¹ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¤šæ¨¡æ€é©±åŠ¨çš„æ™ºèƒ½å°è¯æ ‡æ³¨ç³»ç»Ÿã€‚ç³»ç»Ÿèåˆè¯­éŸ³è¯†åˆ«ã€è¯´è¯äººèšç±»ã€äººè„¸è¿½è¸ªï¼Œå®ç°äº†éŸ³è§†é¢‘ä¿¡æ¯çš„æ·±åº¦äº’è¡¥ã€‚æŠ€æœ¯ä¸Šï¼Œæˆ‘ä»¬è®¾è®¡äº†å‰åæ–‡åœºæ™¯é©±åŠ¨çš„å¯¹è¯åˆ†ç»„ä¸çº¦æŸèšç±»æœºåˆ¶ï¼Œè§£å†³äº†çŸ­éŸ³é¢‘åˆ‡åˆ†ä¸å‡†å’Œå¤šäººé‡å è¯­éŸ³çš„é²æ£’æ€§é—®é¢˜ï¼›å¼•å…¥æ»‘åŠ¨çª—å£+æŠ•ç¥¨æœºåˆ¶ï¼Œæ˜¾è‘—é™ä½äº†å™ªå£°å¹²æ‰°å¯¼è‡´çš„è¯†åˆ«åå·®ï¼›å¹¶ç»“åˆå¤§è¯­è¨€æ¨¡å‹çš„ä¸Šä¸‹æ–‡å› æœæ ¡æ­£ï¼Œæå‡äº†å°è¯ä¸è§’è‰²åŒ¹é…çš„è¯­ä¹‰ä¸€è‡´æ€§ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨å›½äº§ç”µè§†å‰§ã€Šå¼€ç«¯ã€‹æ•°æ®é›†ä¸­ï¼Œè¯´è¯äººå‡†ç¡®ç‡è¾¾åˆ°81.52%ï¼Œç»“åˆå„æ¨¡å—ä½œç”¨å±•å¼€æ¶ˆèå®éªŒï¼Œå‡æ˜¾è‘—ä¼˜äºç°æœ‰å•æ¨¡æ€æ–¹æ¡ˆã€‚è¯¥æ–¹æ³•å…·å¤‡è‰¯å¥½çš„é€šç”¨æ€§ä¸å¯æ‰©å±•æ€§ï¼Œä¸ºå½±è§†åæœŸã€çŸ­è§†é¢‘ç”Ÿæˆç­‰åº”ç”¨æä¾›äº†é«˜æ•ˆã€æ™ºèƒ½çš„è§£å†³æ–¹æ¡ˆã€‚ 

"Immersive Sound": A Multimodal-Driven Intelligent Dialogue Annotation System
Addressing the pain points of traditional subtitle production, such as manual-dependent dialogue alignment and high error rates, we propose a multimodal-driven intelligent dialogue annotation system. The system integrates speech recognition, speaker clustering, and face tracking to achieve deep complementarity of audio-visual information. Technically, we designed a contextually scene-driven dialogue grouping and constrained clustering mechanism to resolve the robustness issues of inaccurate short audio segmentation and multi-speaker overlapping speech. The introduction of a sliding window and voting mechanism significantly reduces recognition deviations caused by noise interference. Combined with contextual causal correction leveraging large language models, the semantic consistency between dialogues and character matching is enhanced. Experiments on the dataset of the Chinese TV series Reset demonstrate a speaker recognition accuracy of 81.52%. Ablation studies on the roles of each module show significant improvements over existing unimodal solutions. The method exhibits strong generalizability and scalability, providing an efficient and intelligent solution for applications such as film and television post-production and short video generation.



## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

- Python 3.8+
- PyTorch 1.9+
- CUDA 11.0+ 

### å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt


### è®­ç»ƒæ¨¡å‹
```bash
python  /root/main.py



### ğŸ—‚ é¡¹ç›®ç»“æ„
text
project/
â”œâ”€â”€ configs/          # é…ç½®æ–‡ä»¶
â”œâ”€â”€ data/             # æ•°æ®ç›®å½•
â”œâ”€â”€ models/           # æ¨¡å‹å®šä¹‰
â”œâ”€â”€ utils/            # å·¥å…·å‡½æ•°
â”œâ”€â”€ scripts/          # è®­ç»ƒå’Œè¯„ä¼°è„šæœ¬
â”œâ”€â”€ images/           # å›¾ç‰‡èµ„æº
â”œâ”€â”€ requirements.txt  # ä¾èµ–åˆ—è¡¨
â””â”€â”€ README.md         # é¡¹ç›®è¯´æ˜

### ğŸ‘¥ è´¡çŒ®è€…
- [Merhan Lee](https://github.com/qjmltz)
- [Ruixi Ran](https://github.com/MagiaClay)



### ğŸ™ è‡´è°¢
æ„Ÿè°¢ [redimnet](https://github.com/redimnet) å’Œ [adaface](https://github.com/adaface) æä¾›çš„å®è´µèµ„æºå’Œä»£ç å‚è€ƒï¼

æ„Ÿè°¢ç¬¬ä¸ƒå±Šä¸­å›½ç ”ç©¶ç”Ÿäººå·¥æ™ºèƒ½åˆ›æ–°å¤§èµ›ä»¥åŠåä¸ºä¼ä¸šæä¾›å¹³å°ï¼



